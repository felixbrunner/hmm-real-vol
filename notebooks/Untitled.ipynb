{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "class BaseModel:\n",
    "    \n",
    "    '''\n",
    "    Base class for models\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def score(self, Y):\n",
    "        \n",
    "        '''\n",
    "        Returns the log-likelihood of an observation sequence\n",
    "        '''\n",
    "        \n",
    "        score = np.log(self.pdf(Y)).sum()\n",
    "        return score\n",
    "\n",
    "\n",
    "class NormalModel(BaseModel):\n",
    "    \n",
    "    '''\n",
    "    i.i.d. normal distribution model\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, mu=0, sigma=1):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    @property\n",
    "    def loc(self):\n",
    "        return self.mu\n",
    "    \n",
    "    @property\n",
    "    def scale(self):\n",
    "        return self.sigma\n",
    "    \n",
    "        \n",
    "    def fit(self, Y, weights=None):\n",
    "        \n",
    "        '''\n",
    "        Fits the model parameters to an observation sequence.\n",
    "        weights are optional.\n",
    "        '''\n",
    "        \n",
    "        # prepare\n",
    "        Y = np.array(Y)\n",
    "        if weights is None:\n",
    "            weights = np.ones(Y.shape)\n",
    "        else:\n",
    "            weights = np.array(weights)\n",
    "        \n",
    "        # estimate mean\n",
    "        mean = np.average(Y, weights=weights)\n",
    "        \n",
    "        # estimate variance\n",
    "        errors = (Y-mean)**2\n",
    "        variance = np.average(errors, weights=weights)\n",
    "        \n",
    "        # update\n",
    "        self.mu = mean\n",
    "        self.sigma = np.sqrt(variance)\n",
    "        \n",
    "    def pdf(self, Y):\n",
    "        \n",
    "        '''\n",
    "        Returns the likelihood of each observation in an observation sequence.\n",
    "        '''\n",
    "        \n",
    "        Y = np.array(Y)\n",
    "        pdf = norm(loc=self.mu, scale=self.sigma).pdf(Y)\n",
    "        return pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "class MarkovChain:\n",
    "    \n",
    "    '''\n",
    "    A MarkovChain\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, transition_matrix=None, state_vector=None):\n",
    "        self.transition_matrix = transition_matrix\n",
    "        self.state_vector = state_vector\n",
    "\n",
    "    @property\n",
    "    def transition_matrix(self):\n",
    "        \n",
    "        '''\n",
    "        The Markov state transition probability matrix.\n",
    "        Needs to be square.\n",
    "        '''\n",
    "        \n",
    "        return self._transition_matrix\n",
    "        \n",
    "    @transition_matrix.setter\n",
    "    def transition_matrix(self, transition_matrix):\n",
    "        if transition_matrix is not None:        \n",
    "            transition_matrix = np.array(transition_matrix)\n",
    "            assert transition_matrix.shape[0] == transition_matrix.shape[1], \\\n",
    "                'transition matrix needs to be square'\n",
    "            assert all(transition_matrix.sum(axis=1) == 1), \\\n",
    "                'transition matrix rows need to sum to one'\n",
    "            if hasattr(self, 'state_vector'):\n",
    "                assert transition_matrix.shape[0] == self.state_vector.shape[1], \\\n",
    "                    'state vector dimension mismatch'\n",
    "            self._transition_matrix = transition_matrix\n",
    "        else:\n",
    "            self._transition_matrix = None\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def state_vector(self):\n",
    "        \n",
    "        '''\n",
    "        The current state vector.\n",
    "        '''\n",
    "        \n",
    "        return self._state_vector\n",
    "    \n",
    "    @state_vector.setter\n",
    "    def state_vector(self, state_vector):\n",
    "        if state_vector is not None:\n",
    "            state_vector = np.array(state_vector).reshape(1,-1)\n",
    "            assert state_vector.sum(axis=1) == 1, \\\n",
    "                'state vector needs to sum to one'\n",
    "            assert (state_vector>=0).all() and (state_vector<=1).all(), \\\n",
    "                'probabilites need to be bounded between zero and one'\n",
    "            if hasattr(self, 'transition_matrix'):\n",
    "                assert state_vector.shape[1] == self.transition_matrix.shape[0], \\\n",
    "                    'transition matrix dimension mismatch'\n",
    "            self._state_vector = state_vector\n",
    "        else:\n",
    "            self._state_vector = None\n",
    "    \n",
    "\n",
    "    def steady_state(self, set_state=False):\n",
    "        \n",
    "        '''\n",
    "        Returns the steady state probabilities of the Markov chain.\n",
    "        If set_state=True, MarkovChain object is modified in place.\n",
    "        '''\n",
    "        \n",
    "        dim = np.array(self.transition_matrix).shape[0]\n",
    "        q = np.c_[(self.transition_matrix-np.eye(dim)),np.ones(dim)]\n",
    "        QTQ = np.dot(q, q.T)\n",
    "        steady_state = np.linalg.solve(QTQ,np.ones(dim))\n",
    "        if set_state:\n",
    "            self.state_vector = steady_state\n",
    "        else:\n",
    "            return steady_state\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def expected_durations(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the expected state durations of the MarkovChain object.\n",
    "        '''\n",
    "        \n",
    "        expected_durations = (np.ones(self.n_states)-np.diag(self.transition_matrix))**-1\n",
    "        return expected_durations\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def n_states(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the number of states of the MarkovChain object.\n",
    "        '''\n",
    "        \n",
    "        return self.state_vector.shape[1]\n",
    "\n",
    "\n",
    "    def iterate(self, steps=1, set_state=False):\n",
    "        \n",
    "        '''\n",
    "        Iterates the MarkovChain object in place.\n",
    "        steps needs to be a positive integer.\n",
    "        (negative steps work, but tend to break before the initial state)\n",
    "        If set_state=True, MarkovChain object is modified in place.\n",
    "        '''\n",
    "        \n",
    "        new_state = np.dot(self.state_vector, np.linalg.matrix_power(self.transition_matrix, steps))\n",
    "        \n",
    "        # ensure total probability is 1\n",
    "        if new_state.sum() != 1:\n",
    "            new_state = new_state.round(8)/new_state.round(8).sum()\n",
    "            warnings.warn('Transition matrix rounded to 8 decimal places')\n",
    "        \n",
    "        if set_state:\n",
    "            self.state_vector = new_state\n",
    "        else:\n",
    "            return new_state\n",
    "        \n",
    "        \n",
    "    def forecast(self, horizons=[1]):\n",
    "        \n",
    "        '''\n",
    "        Returns forecasted state probabilities for a set of horizons.\n",
    "        horizons needs to be an iterable.\n",
    "        '''\n",
    "        \n",
    "        horizons_states = np.array([]).reshape(0, self.n_states)\n",
    "        for horizon in horizons:\n",
    "            pi_ = np.dot(self.state_vector, np.linalg.matrix_power(self.transition_matrix, horizon))\n",
    "            horizons_states = np.concatenate([horizons_states, pi_.reshape(1, self.n_states)], axis=0)\n",
    "        return horizons_states\n",
    "    \n",
    "\n",
    "    def rvs(self, t_steps=0, random_state=1):\n",
    "        \n",
    "        '''\n",
    "        Draws a random sample sequence from the MarkovChain object.\n",
    "        t_steps is the number of time steps forward to be drawn.\n",
    "        If t_steps is zero, only the current state is drawn.\n",
    "        '''\n",
    "        \n",
    "        sample = np.random.choice(self.n_states, size=1, p=self.state_vector.squeeze())\n",
    "        for t in range(1, t_steps+1):\n",
    "            sample = np.concatenate([sample, \\\n",
    "                                     np.random.choice(self.n_states, size=1, p=self.transition_matrix[sample[-1]])])\n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    def entropy(self, horizons=None):\n",
    "        \n",
    "        '''\n",
    "        Calculate Shannon's entropy of the n state probabilities based on logarithms with base n.\n",
    "        '''\n",
    "        \n",
    "        if horizons is None:\n",
    "            state_entropy = entropy(self.state_vector.squeeze(), base=self.n_states)\n",
    "        \n",
    "        else:\n",
    "            horizon_states = self.forecast(horizons)\n",
    "            state_entropy = []\n",
    "            for horizon in horizon_states:\n",
    "                state_entropy += [entropy(horizon.squeeze(), base=self.n_states)]\n",
    "            \n",
    "        return np.array(state_entropy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72086909, 0.27913091],\n",
       "       [0.358     , 0.642     ],\n",
       "       [0.8078944 , 0.1921056 ],\n",
       "       [0.95238095, 0.04761905],\n",
       "       [0.95236235, 0.04763765],\n",
       "       [0.2       , 0.8       ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = MarkovChain(np.array([[0.99,0.01],[0.2,0.8]]),np.array([0,1]))\n",
    "mc.iterate(1, set_state=True)\n",
    "mc.state_vector\n",
    "mc.transition_matrix\n",
    "mc.forecast([5,1,7,123,45,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95238095, 0.04761905])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.steady_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.72192809)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04857902841943161"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.rvs(50000).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95238095, 0.04761905]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.steady_state(set_state=True)\n",
    "mc.state_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95238095, 0.04761905]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.iterate(10, set_state=True)\n",
    "mc.state_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=MarkovChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "#from src.dists import GaussianMixtureDistribution\n",
    "#from src.markov import MarkovChain\n",
    "\n",
    "\n",
    "class HMM(MarkovChain):\n",
    "    def __init__(self, emission_models=(), transition_matrix=None, start_probas=None, switch_var=True, switch_const=True, k=None):\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "\n",
    "        self.emission_models = emission_models\n",
    "        self.transition_matrix = transition_matrix\n",
    "        self.start_probas = start_probas\n",
    "        \n",
    "        self.switch_var = switch_var\n",
    "        self.switch_const = switch_const\n",
    "        self.k = k\n",
    "        \n",
    "        self.params_ = None\n",
    "        self.se_ = None\n",
    "        self.tstats_ = None\n",
    "\n",
    "        self.metrics_ = None\n",
    "        self.smooth_prob_ = None\n",
    "        self.filt_prob_ = None\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDistribution:\n",
    "    \n",
    "    '''\n",
    "    Base class for distributions.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def std(self):\n",
    "\n",
    "        '''\n",
    "        Returns the distribution standard deviation.\n",
    "        '''\n",
    "\n",
    "        return self.var()**0.5\n",
    "\n",
    "\n",
    "    def exkurt(self):\n",
    "\n",
    "        '''\n",
    "        Returns the excess kurtosis.\n",
    "        '''\n",
    "\n",
    "        return self.kurt()-3\n",
    "\n",
    "\n",
    "    def mvsk(self):\n",
    "    \n",
    "        '''\n",
    "        Returns the first four standardised moments about the mean.\n",
    "        '''\n",
    "    \n",
    "        m = self.mean()\n",
    "        v = self.var()\n",
    "        s = self.skew()\n",
    "        k = self.kurt()\n",
    "        return (m, v, s, k)\n",
    "\n",
    "\n",
    "class GaussianMixtureDistribution(BaseDistribution):\n",
    "    \n",
    "    '''\n",
    "    A GaussianMixtureDistribution is a list of triples that parametrise the components of a Gaussian mixture distribution.\n",
    "    Each triple is a tuple of mean, standard deviation and probability weight of the component.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, components=[]):\n",
    "        self.components = components\n",
    "        self.n_components = len(self.components)\n",
    "        \n",
    "    def add_component(self,component):\n",
    "        self.components += [component]\n",
    "        self.n_components += 1\n",
    "        \n",
    "    def central_moment(self, moment):\n",
    "\n",
    "        '''\n",
    "        Compute the central moments of a mixture of normal components.\n",
    "        Moment is the order of the central moment to compute.\n",
    "        '''\n",
    "\n",
    "        mean = sum([w*m for (m, s, w) in self.components])\n",
    "    \n",
    "        if moment is 1:\n",
    "            return mean\n",
    "        else:\n",
    "            mixture_moment = 0\n",
    "            for (m, s, w) in self.components:\n",
    "                for k in range(moment+1):\n",
    "                    product = sp.special.comb(moment, k) * (m-mean)**(moment-k) * normal_central_moment(s, k)\n",
    "                    mixture_moment += w * product\n",
    "            return mixture_moment\n",
    "        \n",
    "    def standardised_moment(self, moment):\n",
    "    \n",
    "        '''\n",
    "        Normalised moment of a mixture distribution.\n",
    "        '''\n",
    "    \n",
    "        if (moment<=2):\n",
    "            mixture_moment = self.central_moment(moment)\n",
    "        else:\n",
    "            mixture_variance = self.central_moment(2)\n",
    "            mixture_central_moment = self.central_moment(moment)\n",
    "            mixture_moment = mixture_central_moment / mixture_variance**(moment/2)\n",
    "            if (moment%2==0):\n",
    "                bias = normal_central_moment(1,moment)\n",
    "                mixture_moment -= bias\n",
    "        return mixture_moment\n",
    "    \n",
    "\n",
    "    def mean(self):\n",
    "        return self.standardised_moment(1)\n",
    "    \n",
    "\n",
    "    def var(self):\n",
    "        return self.standardised_moment(2)\n",
    "    \n",
    "\n",
    "    def std(self):\n",
    "        return self.standardised_moment(2)**0.5\n",
    "    \n",
    "\n",
    "    def skew(self):\n",
    "        return self.standardised_moment(3)\n",
    "    \n",
    "\n",
    "    def kurt(self):\n",
    "        \n",
    "        '''\n",
    "        Note that the output value is the excess kurtosis.\n",
    "        '''\n",
    "        \n",
    "        return self.standardised_moment(4)\n",
    "    \n",
    "\n",
    "    # def mvsk(self):\n",
    "    \n",
    "    #     '''\n",
    "    #     The first four standardised moments about the mean of a mixture distribution.\n",
    "    #     '''\n",
    "    \n",
    "    #     m = self.mean()\n",
    "    #     v = self.var()\n",
    "    #     s = self.skew()\n",
    "    #     k = self.kurt()\n",
    "    #     return (m,v,s,k)\n",
    "\n",
    "            \n",
    "    def rvs(self, sample_size=1):\n",
    "    \n",
    "        '''\n",
    "        Draw a random sample from a mixture distribution\n",
    "        '''\n",
    "    \n",
    "        weights = [p for (m,s,p) in self.components]\n",
    "        norm_params = [(m,s) for (m,s,p) in self.components]\n",
    "        draw_from = np.random.choice(self.n_components, size=sample_size, replace=True, p=weights)\n",
    "        sample = np.fromiter((ss.norm.rvs(*(norm_params[i])) for i in draw_from),dtype=np.float64)\n",
    "        if sample_size is 1:\n",
    "            sample = sample[0]\n",
    "        return sample\n",
    "    \n",
    "\n",
    "    def pdf(self, x):\n",
    "        y = np.zeros(np.array(x).shape)\n",
    "        for (m, s, w) in self.components:\n",
    "            y += w*sp.stats.norm.pdf(x, m, s)\n",
    "        return y\n",
    "    \n",
    "\n",
    "    def cdf(self, x):\n",
    "        y = np.zeros(np.array(x).shape)\n",
    "        for (m, s, w) in self.components:\n",
    "            y += w*sp.stats.norm.cdf(x, m, s)\n",
    "        return y\n",
    "    \n",
    "\n",
    "    def entropy(self):\n",
    "        \n",
    "        '''\n",
    "        Calculate Shannon's entropy based on logarithms with base n of the n component probabilities.\n",
    "        '''\n",
    "        \n",
    "        entropy = 0\n",
    "        for (m, s, w) in self.components:\n",
    "            if w == 0:\n",
    "                pass\n",
    "            else:\n",
    "                entropy += w*np.log(w)/np.log(self.n_components)\n",
    "        return abs(entropy)\n",
    "    \n",
    "    def get_component_means(self):\n",
    "        means = [m for (m,s,w) in self.components]\n",
    "        return means\n",
    "    \n",
    "    def get_component_stds(self):\n",
    "        stds = [s for (m,s,w) in self.components]\n",
    "        return stds\n",
    "    \n",
    "    def get_component_weights(self):\n",
    "        weights = [w for (m,s,w) in self.components]\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normal_central_moment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-7bfed6449727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianMixtureDistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmvsk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-7338f8ec1213>\u001b[0m in \u001b[0;36mmvsk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkurt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-7338f8ec1213>\u001b[0m in \u001b[0;36mvar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardised_moment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-7338f8ec1213>\u001b[0m in \u001b[0;36mstandardised_moment\u001b[0;34m(self, moment)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmoment\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mmixture_moment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentral_moment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mmixture_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentral_moment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-7338f8ec1213>\u001b[0m in \u001b[0;36mcentral_moment\u001b[0;34m(self, moment)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoment\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoment\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnormal_central_moment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                     \u001b[0mmixture_moment\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmixture_moment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normal_central_moment' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "_ = GaussianMixtureDistribution([(1,2,0.5),(0,1,0.5)])\n",
    "_.mvsk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalDistribution(BaseDistribution):\n",
    "    \n",
    "    '''\n",
    "    A normal distribution.\n",
    "    If no parameters are specified, a standard normal distribution.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, mu=0, sigma=1):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def mu(self):\n",
    "        \n",
    "        '''\n",
    "        The distribution mean.\n",
    "        '''\n",
    "        \n",
    "        return self._mu\n",
    "    \n",
    "    @mu.setter\n",
    "    def mu(self, mu):\n",
    "        assert type(mu) == int or type(mu) == float, \\\n",
    "            'mu needs to be numeric'\n",
    "        self._mu = mu\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def sigma(self):\n",
    "        \n",
    "        '''\n",
    "        The distribution standard deviation.\n",
    "        '''\n",
    "        \n",
    "        return self._sigma\n",
    "    \n",
    "    @sigma.setter\n",
    "    def sigma(self, sigma):\n",
    "        assert type(sigma) == int or type(sigma) == float, \\\n",
    "            'sigma needs to be numeric'\n",
    "        self._sigma = sigma\n",
    "    \n",
    "    \n",
    "    def central_moment(self, moment):\n",
    "\n",
    "        '''\n",
    "        Returns the central moments of input order.\n",
    "        '''\n",
    "        \n",
    "        assert moment>0 and type(moment)==int, \\\n",
    "            'moment needs to be a positive integer'\n",
    "\n",
    "        if moment % 2 == 1:\n",
    "            #odd moments of a normal are zero\n",
    "            central_moment = 0 \n",
    "        else:\n",
    "            #even moments are given by sigma^n times the double factorial\n",
    "            central_moment = self.sigma**moment * sp.special.factorialk(moment-1, 2)\n",
    "        return central_moment\n",
    "    \n",
    "    \n",
    "    def standardised_moment(self, moment):\n",
    "    \n",
    "        '''\n",
    "        Returns the normalised moment of input order.\n",
    "        '''\n",
    "        \n",
    "        assert moment>0 and type(moment)==int, \\\n",
    "            'moment needs to be a positive integer'\n",
    "        \n",
    "        central_moment = self.central_moment(moment)\n",
    "        if (moment<=2):\n",
    "            standardised_moment = central_moment\n",
    "        else:\n",
    "            standardised_moment = central_moment / self.var()**(moment/2)\n",
    "        return standardised_moment\n",
    "    \n",
    "    \n",
    "    def mean(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the distribution mean.\n",
    "        '''\n",
    "        \n",
    "        return self.mu\n",
    "    \n",
    "    \n",
    "    def var(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the distribution variance.\n",
    "        '''\n",
    "        \n",
    "        var = self.standardised_moment(2)\n",
    "        return var\n",
    "    \n",
    "    \n",
    "    def skew(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the distribution skewness.\n",
    "        '''\n",
    "        \n",
    "        skew = self.standardised_moment(3)\n",
    "        return skew\n",
    "    \n",
    "    \n",
    "    def kurt(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the distribution kurtosis.\n",
    "        '''\n",
    "        \n",
    "        kurt = self.standardised_moment(4)\n",
    "        return kurt\n",
    "    \n",
    "    \n",
    "    def pdf(self, x):\n",
    "        y = sp.stats.norm(loc=self.mu, scale=self.sigma).pdf(x)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "    def cdf(self, x):\n",
    "        y = sp.stats.norm(loc=self.mu, scale=self.sigma).cdf(x)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "    def rvs(self, size=1):\n",
    "        sample = sp.stats.norm(loc=self.mu, scale=self.sigma).rvs(size=size)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureDistribution(BaseDistribution):\n",
    "    \n",
    "    '''\n",
    "    A mixture distribution is a list of triples that parametrise the components of a Gaussian mixture distribution.\n",
    "    Each triple is a tuple of mean, standard deviation and probability weight of the component.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, components=None):\n",
    "        self.components = components\n",
    "        \n",
    "    \n",
    "    def _check_component(self, component):\n",
    "        \n",
    "        '''\n",
    "        Checks component inputs.\n",
    "        '''\n",
    "        \n",
    "        dist, weight = component\n",
    "        assert isinstance(dist, BaseDistribution), \\\n",
    "            'unknown component distribution type'\n",
    "        assert type(weight) == float or type(weight) == int, \\\n",
    "            'weight needs to be numberic'\n",
    "    \n",
    "    @property\n",
    "    def components(self):\n",
    "        \n",
    "        '''\n",
    "        List of (distribution, weight) tuples.\n",
    "        Distributions need to be instances of Base Distribution.\n",
    "        Weights need to be numbers.\n",
    "        '''\n",
    "        \n",
    "        return self._components\n",
    "    \n",
    "    @components.setter\n",
    "    def components(self, components):\n",
    "        assert type(components) == list, \\\n",
    "            'components needs to be a list of tuples'\n",
    "        for component in components:\n",
    "            self._check_component(component)\n",
    "        self._components = components\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def distributions(self):\n",
    "        \n",
    "        '''\n",
    "        Returns a list of component distributions.\n",
    "        '''\n",
    "        \n",
    "        distributions = [component[0] for component in self.components]\n",
    "        return distributions\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def weights(self):\n",
    "        \n",
    "        '''\n",
    "        Returns a list of component weights.\n",
    "        '''\n",
    "        \n",
    "        weights = [component[1] for component in self.components]\n",
    "        return weights\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def n_components(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the number of components.\n",
    "        '''\n",
    "        \n",
    "        return len(self.components)\n",
    "    \n",
    "    \n",
    "    def add_component(self, distribution, weight):\n",
    "        \n",
    "        '''\n",
    "        Adds a component to the mixture distribution.\n",
    "        Inputs needs to be a distribution and a weight.\n",
    "        '''\n",
    "        \n",
    "        component = (distribution, weight)\n",
    "        self._check_component(component)\n",
    "        self.components = self.components + [component]\n",
    "\n",
    "        \n",
    "    def mean(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the mean.\n",
    "        '''\n",
    "        \n",
    "        mean = sum([component.mean()*weight for (component, weight) in self.components])\n",
    "        return mean\n",
    "        \n",
    "    \n",
    "    def central_moment(self, moment):\n",
    "\n",
    "        '''\n",
    "        Returns the central moment of input order.\n",
    "        '''\n",
    "\n",
    "        assert moment > 0, \\\n",
    "            'moment needs to be positive'\n",
    "    \n",
    "        if moment is 1:\n",
    "            return 0\n",
    "        else:\n",
    "            mean = self.mean()\n",
    "            inputs = [(component.mean(), component.std(), weight) for (component, weight) in self.components]\n",
    "            central_moment = 0\n",
    "            for (m, s, w) in inputs:\n",
    "                for k in range(moment+1):\n",
    "                    product = sp.special.comb(moment, k) * (m-mean)**(moment-k) * sp.stats.norm(loc=0, scale=s).moment(k)\n",
    "                    central_moment += w * product\n",
    "            return central_moment\n",
    "        \n",
    "        \n",
    "    def standardised_moment(self, moment):\n",
    "    \n",
    "        '''\n",
    "        Returns the normalised moment of input order.\n",
    "        '''\n",
    "    \n",
    "        if (moment<=2):\n",
    "            standardised_moment = self.central_moment(moment)\n",
    "        else:\n",
    "            variance = self.central_moment(2)\n",
    "            central_moment = self.central_moment(moment)\n",
    "            standardised_moment = central_moment / variance**(moment/2)\n",
    "            if (moment%2==0):\n",
    "                bias = sp.stats.norm(loc=0, scale=1).moment(moment)\n",
    "                standardised_moment -= bias\n",
    "        return standardised_moment\n",
    "    \n",
    "\n",
    "    def var(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the distribution variance.\n",
    "        '''\n",
    "        \n",
    "        return self.standardised_moment(2)\n",
    "    \n",
    "\n",
    "    def skew(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the distribution skewness.\n",
    "        '''\n",
    "        \n",
    "        return self.standardised_moment(3)\n",
    "    \n",
    "\n",
    "    def kurt(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the distribution kurtosis.\n",
    "        '''\n",
    "        \n",
    "        return self.standardised_moment(4)\n",
    "    \n",
    "    \n",
    "    def entropy(self, level='state'):\n",
    "        \n",
    "        '''\n",
    "        Returns Shannon's entropy based on logarithms with base n of the n component probabilities.\n",
    "        '''\n",
    "        \n",
    "        if level == 'state':\n",
    "            entropy = sp.stats.entropy(self.weights, base=self.n_components)\n",
    "        else:\n",
    "            raise NotImplementedError('random variable entropy not implemented')\n",
    "        return entropy\n",
    "    \n",
    "    \n",
    "    def component_means(self):\n",
    "        \n",
    "        '''\n",
    "        Returns a list of component means.\n",
    "        '''\n",
    "        \n",
    "        means = [distribution.mean() for (distribution, weight) in self.components]\n",
    "        return means\n",
    "    \n",
    "    \n",
    "    def component_stds(self):\n",
    "        \n",
    "        '''\n",
    "        Returns a list of component standard deviations.\n",
    "        '''\n",
    "        \n",
    "        stds = [distribution.std() for (distribution, weight) in self.components]\n",
    "        return stds\n",
    "    \n",
    "    \n",
    "    def pdf(self, x):\n",
    "        \n",
    "        '''\n",
    "        Evaluates the probability density function at x.\n",
    "        '''\n",
    "        \n",
    "        y = np.zeros(np.array(x).shape)\n",
    "        for (component, weight) in self.components:\n",
    "            y += weight*component.pdf(x)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "    def cdf(self, x):\n",
    "        \n",
    "        '''\n",
    "        Evaluates the cumulative density function at x.\n",
    "        '''\n",
    "        \n",
    "        y = np.zeros(np.array(x).shape)\n",
    "        for (component, weight) in self.components:\n",
    "            y += weight*component.cdf(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "    def rvs(self, size=1, return_states=False):\n",
    "    \n",
    "        '''\n",
    "        Draw a random sample from a mixture distribution.\n",
    "        '''\n",
    "    \n",
    "        states = np.random.choice(self.n_components, size=size, replace=True, p=self.weights)\n",
    "        sample = np.fromiter((self.components[i][0].rvs() for i in states), dtype=np.float64)\n",
    "        \n",
    "        if size is 1:\n",
    "            sample = sample[0]\n",
    "            \n",
    "        if return_states:\n",
    "            return (sample, states)\n",
    "        else:\n",
    "            return sample\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductDistribution(BaseDistribution):\n",
    "    \n",
    "    '''\n",
    "    A ProducDistribution is a list of tuples that contains the first central moments of the factor distributions.\n",
    "    Note that the input moments have to be non-standardised and factor draws have to be independent.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, factors=None):\n",
    "        self.factors = factors\n",
    "        \n",
    "        \n",
    "    def _check_factor(self, factor):\n",
    "        \n",
    "        '''\n",
    "        Checks factor inputs.\n",
    "        '''\n",
    "        \n",
    "        assert isinstance(factor, BaseDistribution), \\\n",
    "            'unknown factor distribution type'\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def factors(self):\n",
    "        \n",
    "        '''\n",
    "        List of factor distributions.\n",
    "        Each element needs to be instances of BaseDistribution.\n",
    "        '''\n",
    "        \n",
    "        return self._factors\n",
    "    \n",
    "    @factors.setter\n",
    "    def factors(self, factors):\n",
    "        assert type(factors) == list, \\\n",
    "            'factors needs to be a list of tuples'\n",
    "        for factor in factors:\n",
    "            self._check_factor(factor)\n",
    "        self._factors = factors\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def n_factors(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the number of factors.\n",
    "        '''\n",
    "        \n",
    "        return len(self.factors)\n",
    "    \n",
    "    \n",
    "    def add_factor(self, factor):\n",
    "        \n",
    "        '''\n",
    "        Adds a factor to the mixture distribution.\n",
    "        Input needs to instance of BaseDistribution.\n",
    "        '''\n",
    "        \n",
    "        self._check_factor(factor)\n",
    "        self.factors = self.factors + [factor]\n",
    "\n",
    "\n",
    "    def mean(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the distribution mean.\n",
    "        '''\n",
    "        \n",
    "        prod = 1\n",
    "        for factor in self.factors:\n",
    "            m = factor.mean()\n",
    "            prod *= m\n",
    "        mean = prod\n",
    "        return mean\n",
    "    \n",
    "\n",
    "    def var(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the distribution variance.\n",
    "        '''\n",
    "        \n",
    "        prod1, prod2 = 1, 1\n",
    "        for factor in self.factors:\n",
    "            (m, s) = (factor.mean(), factor.var())\n",
    "            prod1 *= m**2+s\n",
    "            prod2 *= m**2\n",
    "        var = prod1 - prod2\n",
    "        return var\n",
    "    \n",
    "\n",
    "    def skew(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the distribution skewness.\n",
    "        '''\n",
    "        \n",
    "        prod1, prod2, prod3 = 1, 1, 1\n",
    "        for factor in self.factors:\n",
    "            (m, s, g) = (factor.mean(), factor.var(), factor.central_moment(3))\n",
    "            prod1 *= g+3*m*s+m**3\n",
    "            prod2 *= m*s+m**3\n",
    "            prod3 *= m**3\n",
    "        third_central_moment = prod1 - 3*prod2 + 2*prod3\n",
    "        skew = third_central_moment/(self.var()**1.5)\n",
    "        return skew\n",
    "\n",
    "    def kurt(self):\n",
    "        \n",
    "        '''\n",
    "        Returns the distribution kurtosis.\n",
    "        '''\n",
    "        \n",
    "        prod1, prod2, prod3, prod4 = 1, 1, 1, 1\n",
    "        for factor in self.factors:\n",
    "            (m, s, g, k) = (factor.mean(), factor.var(), factor.central_moment(3), factor.central_moment(4))\n",
    "            prod1 *= k+4*m*g+6*m**2*s+m**4\n",
    "            prod2 *= m*g+3*m**2*s+m**4\n",
    "            prod3 *= m**2*s+m**4\n",
    "            prod4 *= m**4\n",
    "        fourth_central_moment = prod1 - 4*prod2 + 6*prod3 - 3*prod4\n",
    "        kurt = fourth_central_moment/(self.var()**2)-3\n",
    "        return kurt\n",
    "\n",
    "\n",
    "    def rvs(self, size=1):\n",
    "        \n",
    "        '''\n",
    "        Returns a random sample drawn from a mixture distribution\n",
    "        '''\n",
    "        \n",
    "        sample = np.ones(size)\n",
    "        for factor in self.factors:\n",
    "            sample *= factor.rvs(size=size)\n",
    "\n",
    "        if size is 1:\n",
    "            sample = sample[0]\n",
    "            \n",
    "        return sample\n",
    "\n",
    "    \n",
    "    def pdf(self):\n",
    "        raise NotImplementedError('exact pdf unknown')\n",
    "        \n",
    "    \n",
    "    def cdf(self):\n",
    "        raise NotImplementedError('exact cdf unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac1 = NormalDistribution(1.1, 2)\n",
    "fac2 = NormalDistribution(1.1, 5)\n",
    "factors = [fac1, fac2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2100000000000002, 1.1586940668923695)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductDistribution(factors).mean(), np.array(ProductDistribution(factors).rvs(100000)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.62282237668631, 11.678229239863068)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductDistribution(factors).std(), np.array(ProductDistribution(factors).rvs(100000)).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46238295716396305, 0.4475376900209141)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ProductDistribution(factors).skew(), sp.stats.skew(ProductDistribution(factors).rvs(100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.595171030073189, 5.3517753429096775)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ProductDistribution(factors).kurt(), sp.stats.kurtosis(ProductDistribution(factors).rvs(100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalModel(BaseModel, NormalDistribution):\n",
    "    \n",
    "    '''\n",
    "    i.i.d. normal distribution model\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, mu=0, sigma=1):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    @property\n",
    "    def loc(self):\n",
    "        return self.mu\n",
    "    \n",
    "    @property\n",
    "    def scale(self):\n",
    "        return self.sigma\n",
    "    \n",
    "        \n",
    "    def fit(self, Y, weights=None):\n",
    "        \n",
    "        '''\n",
    "        Fits the model parameters to an observation sequence.\n",
    "        weights are optional.\n",
    "        '''\n",
    "        \n",
    "        # prepare\n",
    "        Y = np.array(Y)\n",
    "        if weights is None:\n",
    "            weights = np.ones(Y.shape)\n",
    "        else:\n",
    "            weights = np.array(weights)\n",
    "        \n",
    "        # estimate mean\n",
    "        mean = np.average(Y, weights=weights)\n",
    "        \n",
    "        # estimate variance\n",
    "        errors = (Y-mean)**2\n",
    "        variance = np.average(errors, weights=weights)\n",
    "        \n",
    "        # update\n",
    "        self.mu = mean\n",
    "        self.sigma = np.sqrt(variance)\n",
    "        \n",
    "        \n",
    "class MixtureModel(BaseModel, MixtureDistribution):\n",
    "    \n",
    "    '''\n",
    "    mixture model of arbitrary distributions\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, components=[]):\n",
    "        self.components = components\n",
    "        \n",
    "        \n",
    "    def fit(self, y):\n",
    "        ### use EM algorithm\n",
    "        raise NotImplementedError('fit method not implemented')\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05399096651318806"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NormalModel(mu=0, sigma=1).pdf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MixtureModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel(MixtureModel, MarkovChain):\n",
    "    \n",
    "    '''\n",
    "    Hidden Markov Model class\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, emission_models=None, transition_matrix=None, state_vector=None):\n",
    "        self.transition_matrix = transition_matrix\n",
    "        self.state_vector = state_vector\n",
    "        self.emission_models = emission_models\n",
    "        self.is_fitted = False\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def emission_models(self):\n",
    "        \n",
    "        '''\n",
    "        A tuple of emission models associated with the Markov states.\n",
    "        '''\n",
    "        \n",
    "        return self._emission_models\n",
    "    \n",
    "    @emission_models.setter\n",
    "    def emission_models(self, emission_models):\n",
    "        if emission_models is not None:\n",
    "            emission_models = tuple(emission_models)\n",
    "            if self.transition_matrix is not None:\n",
    "                assert len(emission_models) == self.transition_matrix.shape[0], \\\n",
    "                    'number of emission models inconsitent'\n",
    "            elif self.state_vector is not None:\n",
    "                assert len(emission_models) == self.state_vector.shape[1], \\\n",
    "                    'number of emission models inconsitent'\n",
    "            self._emission_models = emission_models\n",
    "            \n",
    "        else:\n",
    "            self._emission_models = None\n",
    "            \n",
    "            \n",
    "    @property\n",
    "    def components(self):\n",
    "        \n",
    "        '''\n",
    "        The mixture distribution components.\n",
    "        '''\n",
    "        \n",
    "        weights = self.state_vector.squeeze()\n",
    "        components = [(component, float(weight)) for (component, weight) in zip(self.emission_models, weights)]\n",
    "        return components\n",
    "        \n",
    "    \n",
    "    \n",
    "    def fit(self, Y, method):\n",
    "        \n",
    "        '''\n",
    "        EDIT\n",
    "        '''\n",
    "        \n",
    "        self.is_fitted = True\n",
    "    \n",
    "    \n",
    "    def _estimate_baum_welch(self, Y, max_iter=100, threshold=1e-6, return_fit=False):\n",
    "        \n",
    "        '''\n",
    "        Performs parameter estimation with the Baum-Welch algorithm.\n",
    "        Returns a fitted model.\n",
    "        Returns the the fitted model and parameters of the estimation if return_fit=True.\n",
    "        '''\n",
    "        \n",
    "        # initialise\n",
    "        Y = np.array(Y)\n",
    "        A_, pi_, models_ = self._initialise_baum_welch()\n",
    "        self._check_baum_welch_inputs(A_, pi_, models_)\n",
    "        score_, B_ = self._score(Y, models_, pi_)\n",
    "        \n",
    "        # store\n",
    "        iteration = 0\n",
    "        scores = {iteration: score_}\n",
    "        \n",
    "        while iteration < max_iter:\n",
    "            iteration += 1\n",
    "            Alpha, Gamma, Xi = self._do_e_step(Y, A_, B_, pi_)          \n",
    "            A_, models_, pi_ = self._do_m_step(Y, models_, Gamma, Xi)\n",
    "            score_, B_ = self._score(Y, models_, Gamma)\n",
    "            scores[iteration] = score_\n",
    "            \n",
    "            if abs(scores[iteration]-scores[iteration-1]) < threshold:\n",
    "                converged = True\n",
    "                break\n",
    "        else:\n",
    "            converged = False\n",
    "            warnings.warn('maximum number of iterations reached')\n",
    "                \n",
    "        self._update_attributes(A_, models_, pi_)\n",
    "        \n",
    "        if return_fit:\n",
    "            fit = {'converged': converged,\n",
    "                   'iterations': iteration,\n",
    "                   'scores': scores,\n",
    "                   'pdfs': B_,\n",
    "                   'smoothened_probabilities': Gamma,\n",
    "                   'filtered_probabilities': Alpha}\n",
    "            \n",
    "            return self, fit\n",
    "        else:\n",
    "            return self\n",
    "    \n",
    "    \n",
    "    def _initialise_baum_welch(self):\n",
    "        \n",
    "        '''\n",
    "        Returns initial values for the Baum-Welch algorithm.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        assert self.emission_models is not None, \\\n",
    "            'emission models not specified'\n",
    "            \n",
    "        if self.state_vector is None:\n",
    "            self.steady_state(set_state=True)\n",
    "        if self.transition_matrix is None:\n",
    "            self.transition_matrix = np.full([self.n_states, self.n_states], 1/self.n_states)\n",
    "        \n",
    "        A = self.transition_matrix\n",
    "        models = self.emission_models\n",
    "        pi = self.state_vector\n",
    "        return A, pi, models\n",
    "    \n",
    "    \n",
    "    def _check_baum_welch_inputs(self, A, pi, models):\n",
    "        \n",
    "        '''\n",
    "        Checks the dimension match of algorithm inputs.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "\n",
    "        assert len(models) == A.shape[0] == A.shape[1] == pi.shape[1], \\\n",
    "            'dimension mismatch'\n",
    "    \n",
    "    \n",
    "    def _score(self, Y, emission_models, Gamma):\n",
    "        \n",
    "        '''\n",
    "        Returns the overall model score and component model pdf values for each observation.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        B = self._evaluate_emission_models(Y, emission_models)\n",
    "        score = np.log((B * Gamma).sum(axis=1)).sum(axis=0)\n",
    "        return score, B\n",
    "    \n",
    "    \n",
    "    def _evaluate_emission_models(self, Y, emission_models):\n",
    "        \n",
    "        '''\n",
    "        Returns component model pdf values for each observation.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        B = np.concatenate([model.pdf(Y).reshape(-1, 1) for model in emission_models], axis=1)\n",
    "        return B\n",
    "    \n",
    "    \n",
    "    def _do_e_step(self, Y, A, B, pi):\n",
    "        \n",
    "        '''\n",
    "        Performs all steps of the E-step and returns temporary variables.\n",
    "        All data state probabilities are updated based on the existing component models.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        Alpha, C = self._forward_pass(A, B, pi)\n",
    "        Beta = self._backward_pass(A, B, pi, C)\n",
    "        Gamma = self._emission_odds(Alpha, Beta)\n",
    "        Xi = self._transition_odds(A, B, Alpha, Beta)\n",
    "        return Alpha, Gamma, Xi\n",
    "    \n",
    "    \n",
    "    def _forward_pass(self, A, B, pi):\n",
    "        \n",
    "        '''\n",
    "        Returns filtered probabilities of the data together with each scaling factor.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        # initialise forward pass with first observation\n",
    "        alpha_0 = pi * B[0]\n",
    "        c_0 = 1/alpha_0.sum()\n",
    "        \n",
    "        # save values & scaling factor\n",
    "        Alpha = alpha_0*c_0\n",
    "        C = [c_0]\n",
    "        \n",
    "        # iterate\n",
    "        for b_t in B[1:]:\n",
    "            # calculate\n",
    "            alpha_t = (b_t * Alpha[-1] @ A).reshape(1, -1)\n",
    "            c_t = 1/alpha_t.sum()\n",
    "            \n",
    "            # save\n",
    "            Alpha = np.concatenate((Alpha, alpha_t*c_t), axis=0)\n",
    "            C += [c_t]\n",
    "            \n",
    "        C = np.array(C).reshape(-1, 1)\n",
    "        return Alpha, C\n",
    "\n",
    "    \n",
    "    def _backward_pass(self, A, B, pi, C):\n",
    "        \n",
    "        '''\n",
    "        Returns smoothened probabilities of the data.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        # initialise backward pass as one\n",
    "        beta_T = np.ones(pi.shape)\n",
    "        \n",
    "        # save values & scaling factor\n",
    "        Beta = beta_T*C[-1]\n",
    "        \n",
    "        # iterate\n",
    "        for b_t, c_t in zip(B[:0:-1],C[len(C)-2::-1]):\n",
    "            # calculate\n",
    "            beta_t = (b_t * Beta[0] @ A.T).reshape(1, -1)\n",
    "            \n",
    "            # save\n",
    "            Beta = np.concatenate((beta_t*c_t, Beta), axis=0)\n",
    "            \n",
    "        return Beta\n",
    "    \n",
    "    \n",
    "    def _emission_odds(self, Alpha, Beta):\n",
    "        \n",
    "        '''\n",
    "        Returns odds for each observation to be emitted by each component model.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        total = Alpha * Beta\n",
    "        Gamma = total/total.sum(axis=1).reshape(-1, 1)\n",
    "        return Gamma\n",
    "    \n",
    "    \n",
    "    def _transition_odds(self, A, B, Alpha, Beta):\n",
    "        \n",
    "        '''\n",
    "        Returns the odds of each state to transition from each state to each state.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        Alpha_block = np.kron(Alpha[:-1], np.ones(A.shape[0]))\n",
    "        B_Beta_block = np.kron(np.ones(A.shape[0]), B[1:]*Beta[1:])\n",
    "        total = Alpha_block * B_Beta_block * A.reshape(1, -1)\n",
    "        Xi = total/total.sum(axis=1).reshape(-1, 1)\n",
    "        return Xi\n",
    "    \n",
    "    \n",
    "    def _do_m_step(self, Y, models, Gamma, Xi):\n",
    "        \n",
    "        '''\n",
    "        Performs all steps of the M-step and returns temporary variables.\n",
    "        All component models are reestimated and parameters updated.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        A_ = self._update_transition_matrix(Gamma, Xi)\n",
    "        models_ = self._update_model_parameters(Y, models, Gamma)\n",
    "        pi_ = self._update_initial_state(Gamma)\n",
    "        return A_, models_, pi_\n",
    "    \n",
    "\n",
    "    def _update_transition_matrix(self, Gamma, Xi):\n",
    "        \n",
    "        '''\n",
    "        Returns an updated Markov transition matrix.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        numerator = Xi.sum(axis=0)\n",
    "        denominator = np.kron(Gamma[:-1], np.ones(Gamma.shape[1])).sum(axis=0)\n",
    "        A_ = (numerator/denominator).reshape(Gamma.shape[1], Gamma.shape[1])\n",
    "        return A_\n",
    "    \n",
    "    \n",
    "    def _update_model_parameters(self, Y, emission_models, Gamma):\n",
    "        \n",
    "        '''\n",
    "        Returns updated emission models.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        models_ = []\n",
    "        for model, weights in zip(emission_models, Gamma.T):\n",
    "            model.fit(Y, weights)\n",
    "            models_ += [model]\n",
    "        return tuple(models_)\n",
    "    \n",
    "    \n",
    "    def _update_initial_state(self, Gamma):\n",
    "        \n",
    "        '''\n",
    "        Returns updated initial state probabilities.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        return Gamma[0].reshape(1, -1)\n",
    "    \n",
    "    \n",
    "    def _update_attributes(self, A_, models_, pi_):\n",
    "        \n",
    "        '''\n",
    "        Updates the HMM attributes in place.\n",
    "        Part of Baum-Welch algorithm.\n",
    "        '''\n",
    "        \n",
    "        # ensure total transition probabilities are 1\n",
    "        if (A_.sum(axis=1) != 1).any():\n",
    "            A_ = A_.round(6)/A_.round(6).sum(axis=1)\n",
    "            warnings.warn('Transition matrix rounded to 6 decimal places')\n",
    "        self.transition_matrix = A_\n",
    "        \n",
    "        self.emission_models = models_\n",
    "        \n",
    "        state_vector = Alpha[-1]\n",
    "        # ensure total state probability is 1\n",
    "        if state_vector.sum() != 1:\n",
    "            state_vector = state_vector.round(8)/state_vector.round(8).sum()\n",
    "            warnings.warn('State vector rounded to 8 decimal places')\n",
    "        self.state_vector = state_vector\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def distribution(self):\n",
    "        \n",
    "        '''\n",
    "        Extracts and returns a MixtureDistribution object\n",
    "        with the current state vector as weights.\n",
    "        '''\n",
    "        \n",
    "        mix = MixtureDistribution(components=self.components)\n",
    "        return mix\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def mixture_distribution(self):\n",
    "        \n",
    "        '''\n",
    "        Extracts and returns a MixtureDistribution object\n",
    "        with the current state vector as weights.\n",
    "        '''\n",
    "        \n",
    "        return self.distribution\n",
    "    \n",
    "    @property\n",
    "    def markov_chain(self):\n",
    "        \n",
    "        '''\n",
    "        Extracts and returns a MarkovChain object\n",
    "        with the transition matrix and state vector as parameters.\n",
    "        '''\n",
    "                \n",
    "        mc = MarkovChain(transition_matrix=self.transition_matrix, state_vector=self.state_vector)\n",
    "        return mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fit(self, y, package='baumwelch', start_params=None, iter=100, **kwargs):\n",
    "        \n",
    "        '''\n",
    "        Fits the Gaussian HMM to the series y.\n",
    "        '''\n",
    "        \n",
    "        assert package in ['statsmodels', 'hmmlearn', 'baumwelch'], 'package unknown'\n",
    "        \n",
    "        if package == 'statsmodels':            \n",
    "            from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
    "            \n",
    "            #if start_params is None:\n",
    "                #start_params = np.random.randn(self.k+self.k**2)*0.01\n",
    "                #m = y.mean()\n",
    "                #s = y.std()\n",
    "                #v = y.var()\n",
    "                #start_params = np.full(self.**2-self.k, 1/self.k).tolist()\\\n",
    "                #                        +(np.random.randn(self.k)*s/2+m).tolist()\\\n",
    "                #                        +(np.random.randn(self.k)*v+s).tolist()\n",
    "            model = MarkovRegression(endog=y, switching_variance=self.switch_var, switching_trend=self.switch_const, k_regimes=self.k)\\\n",
    "                                .fit(start_params=start_params, maxiter=iter, **kwargs)\n",
    "            self.params_ = model.params\n",
    "            self.se_ = model.bse\n",
    "            self.tstats_ = model.tvalues\n",
    "            self.metrics_ = pd.Series({'llf': model.llf, 'aic': model.aic, 'bic': model.bic,})\n",
    "            self.smooth_prob_ = model.smoothed_marginal_probabilities\n",
    "            self.filt_prob_ = model.filtered_marginal_probabilities\n",
    "        \n",
    "        if package == 'hmmlearn':\n",
    "            from hmmlearn.hmm import GaussianHMM\n",
    "            \n",
    "            assert self.switch_var is True and self.switch_const is True, 'only implemented for fully parametrised components'\n",
    "            t_index = y.index\n",
    "            y = np.expand_dims(y.values, axis=1)\n",
    "            model = GaussianHMM(n_components=self.k, n_iter=iter, **kwargs).fit(y)\n",
    "            trans_probas = model.transmat_.T.reshape(self.k**2,1)[:self.k**2-self.k]\n",
    "            states = np.arange(self.k)\n",
    "            p_index=[f'p[{j}->{i}]' for i in states[:-1] for j in states]\\\n",
    "                        +[f'const[{i}]' for i in states]\\\n",
    "                        +[f'sigma2[{i}]' for i in states]\n",
    "            self.params_ = pd.Series(np.concatenate((trans_probas, model.means_, model.covars_.squeeze(axis=1))).squeeze(), index=p_index)\n",
    "            llf = model.score(y)\n",
    "            self.metrics_ = pd.Series({'llf': llf,\n",
    "                                       'aic': 2*len(self.params_)-2*llf,\n",
    "                                       'bic': len(self.params_)*np.log(len(y))-2*llf})\n",
    "            self.smooth_prob_ = pd.DataFrame(model.predict_proba(y), index=t_index)\n",
    "\n",
    "        if package == 'baumwelch':\n",
    "            self = self._estimate_baum_welch(np.array(y), max_iter=iter, **kwargs)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def estimates_(self):\n",
    "        estimates = pd.DataFrame({'estimate': self.params_,\n",
    "                                  's.e.': self.se_,\n",
    "                                  't-stat': self.tstats_})\n",
    "        return estimates\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def transition_matrix_(self):\n",
    "        k = self.k\n",
    "        trans_matrix = np.matrix(self.params_[:k**2-k].values.reshape(k-1, k).T)\n",
    "        trans_matrix = np.append(trans_matrix, 1-trans_matrix.sum(axis=1), axis=1)\n",
    "        return trans_matrix\n",
    "\n",
    "\n",
    "\n",
    "    def get_mixture_distribution(self, state='steady_state'):\n",
    "        if state == 'steady_state':\n",
    "            probas = self.steady_state_\n",
    "        elif state == 'latest':\n",
    "            probas = self.filt_prob_.iloc[-1]\n",
    "        else:\n",
    "            assert len(state) == self.k, 'wrong number of state probabilities'\n",
    "            probas = state\n",
    "\n",
    "        components = [(self.params_[f'const[{i}]'], self.params_[f'sigma2[{i}]']**0.5, probas[i]) for i in range(self.k)]\n",
    "        mix = GaussianMixtureDistribution(components=components)\n",
    "        return mix\n",
    "\n",
    "\n",
    "    def filtered_moments(self):\n",
    "        filt_mom = pd.DataFrame(index=self.filt_prob_.index, columns=['mean','var','skew','kurt','entropy'])\n",
    "        for date, probas in self.filt_prob_.iterrows():\n",
    "            mix = self.get_mixture_distribution(state=probas.values)\n",
    "            filt_mom.loc[date] = [*mix.mvsk(), mix.entropy()]\n",
    "\n",
    "        return filt_mom\n",
    "\n",
    "\n",
    "    def smoothened_moments(self):\n",
    "        smooth_mom = pd.DataFrame(index=self.smooth_prob_.index, columns=['mean','var','skew','kurt','entropy'])\n",
    "        for date, probas in self.smooth_prob_.iterrows():\n",
    "            mix = self.get_mixture_distribution(state=probas.values)\n",
    "            smooth_mom.loc[date] = [*mix.mvsk(), mix.entropy()]\n",
    "        return smooth_mom\n",
    "        \n",
    "\n",
    "    # def fit(self, Y, method='baumwelch', **kwargs):\n",
    "    #     '''OK'''\n",
    "    #     assert method in ['baumwelch'], 'method unknown'\n",
    "        \n",
    "    #     if method == 'baumwelch':\n",
    "    #         self = self._estimate_baum_welch(Y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdls = (NormalModel(0,1), NormalModel(1,1))\n",
    "hmm = HiddenMarkovModel(transition_matrix=np.array([[0.99,0.01],[0.2,0.8]]), state_vector=[0.5,0.5], emission_models=mdls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MixtureDistribution at 0x7f40e12da4e0>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.mixture_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MarkovChain at 0x7f40e12da048>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.markov_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MixtureDistribution at 0x7f40e12da588>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "mu needs to be numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-b04019e17463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memission_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memission_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memission_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memission_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimate_baum_welch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-246-1743a17b6748>\u001b[0m in \u001b[0;36m_estimate_baum_welch\u001b[0;34m(self, Y, max_iter, threshold, return_fit)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mAlpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_e_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mscore_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-246-1743a17b6748>\u001b[0m in \u001b[0;36m_do_m_step\u001b[0;34m(self, Y, models, Gamma, Xi)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mA_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_transition_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mmodels_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_model_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mpi_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-246-1743a17b6748>\u001b[0m in \u001b[0;36m_update_model_parameters\u001b[0;34m(self, Y, emission_models, Gamma)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mmodels_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memission_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0mmodels_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-150-6523240cf16a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Y, weights)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-105bfdbba752>\u001b[0m in \u001b[0;36mmu\u001b[0;34m(self, mu)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;34m'mu needs to be numeric'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: mu needs to be numeric"
     ]
    }
   ],
   "source": [
    "Y = sp.stats.norm(0.5,2).rvs(100)\n",
    "print(hmm.emission_models[0].mu, hmm.emission_models[1].mu)\n",
    "print(hmm.emission_models[0].sigma, hmm.emission_models[1].sigma)\n",
    "hmm._estimate_baum_welch(Y, max_iter=100, return_fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = pd.DataFrame(sp.stats.multivariate_normal(mean=[1.1, 1.1], cov=[[0.2, 0.1],[0.1, 0.2]]).rvs(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.49934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.49934</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1\n",
       "0  1.00000  0.49934\n",
       "1  0.49934  1.00000"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.198820</td>\n",
       "      <td>0.099823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.099823</td>\n",
       "      <td>0.201007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.198820  0.099823\n",
       "1  0.099823  0.201007"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 20\n",
    "_ = pd.DataFrame(sp.stats.multivariate_normal(mean=[1.1, 1.1], cov=[[0.2, 0.1],[0.1, 0.2]]).rvs(10000*l))\n",
    "sample_2 = _.groupby(_.index // l).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.18994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18994</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1\n",
       "0  1.00000  0.18994\n",
       "1  0.18994  1.00000"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744.851879</td>\n",
       "      <td>152.137269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152.137269</td>\n",
       "      <td>861.331488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1\n",
       "0  744.851879  152.137269\n",
       "1  152.137269  861.331488"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_2.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
